{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takedatmh/toyama/blob/main/Toyama_Uni_2_8_FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8cZUpa7lnB0",
        "outputId": "70c9632d-04af-48c7-859b-db542471a5a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# LLMファインチューニングに必要なライブラリ群\n",
        "!pip install -q \\\n",
        "  transformers \\\n",
        "  datasets \\\n",
        "  accelerate \\\n",
        "  bitsandbytes \\\n",
        "  peft \\\n",
        "  sentencepiece \\\n",
        "  scipy \\\n",
        "  evaluate \\\n",
        "  huggingface-hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b75c263d4bf24f65904f2ab140191308",
            "fbc470e273654e91ac42feed6ff3c42d",
            "433c8a96b1de4c27a73437a0d876aa39",
            "84a7778e64ce4a4cacf381b740b7335e",
            "915c8d10e59d4df1a9499d78e0a7fece",
            "6680e84cfddd4e55a86c21cf6e22a0da",
            "631783d63f254b368395300301407ac9",
            "e1134fd903af4321b996fc89e13315cd",
            "6b289a8fbc3e48b99bad8d7214dbefa0",
            "d17dd6dc524d4e3bab93a42e135ffe78",
            "5ed6d9bd7e6c4856b3f78544efaa8cee",
            "20f4a91db2734ed08bba141babb99687",
            "6f2ca3f100b742b781b52d4b0268477a",
            "77b4caf3e7bd45e48294c401da4630ca",
            "0ddbb22c5e1640779df91ee5bd965843",
            "2894d18e16ac438495f63acef8603d2a",
            "da3f6273ab3b4a999dea3747ea5b69e8",
            "3029bc355b054644be686ff5a5196e94",
            "56e619232e764b53b79fa9ab8b4589e2",
            "da57557940a94b18b2b7bd09fa850fad",
            "f9a4821a21744606b83a45d41d6d07f8",
            "65ef958cbc9f42f0b09805054bb4ea65",
            "524d701b8d944900aed31a2c0ff47682",
            "ddf59abb9a4c4d18ba63b8514ad62ca0",
            "5188f0a3f6464dcfa4fdb36ff0b4cd0d",
            "2518713722354b879ea2d5c30eda4509",
            "45cdf522a9fc48cc8f22b7cae16f1ad2",
            "6259418289884b708b9cc8f276d08d3f",
            "24971ac1c1d64a1fa2044dbce9f95b34",
            "cfafcecc6b68421ea24dd2a0a9ca40ee",
            "cabe20485a7f4e8d8dc736514398f971",
            "036b6019c6df429c8637c38b67967517",
            "d6af46dfe75c41859a572e0da1e1719d",
            "3beff2f7da5049e8a201588875fc403a",
            "3e5bd94258834749be6173816febe0d9",
            "5ff51532e8a849f5b9d27837b68770e7",
            "79ab8db1e5544b7cb21fdb9654db8bd5",
            "9c7c0af83a3947738ab16702c9d05a91",
            "8c5f62543eb44d7991b3d655b1007682",
            "9a32c94b19a4499ca6c89b370bc7e017",
            "a3743728cfe34b649b1f7e423ca847ab",
            "590f308cf0ff4fd599e62f8edac7bc90",
            "f6f89b7acf984df885a1f4be5e311356",
            "2802cb43fd25456ea63b792d19bb5604",
            "5bc9b8b3fea84bc9b2a5e185bc9a59b0",
            "431c586c0a934964bc17ced696419051",
            "861699200b85463d8ca25777173d72ae",
            "3d0af3e3b7fc4265b40e43d6732a4cff",
            "4c662ef8c0024cbeab6d7885f9a724a2",
            "f4a6a784e2754514aac8c64346831582",
            "3f02405a68654d65942557a1df0dda6d",
            "84439b9fae2b41fe973da69b013ed677",
            "15d404accdae436c87693eca1730623a",
            "4605b7df94b0498db28957dc3cdb7b99",
            "5b65f0400e9b4122a41c787dfdae093b",
            "b00ddfb86f6c46d4bdc8a605a7d05408",
            "b4bf7766518447fa8ddc228a593046b8",
            "6e92074af3cc4feebd9b680e8b1290e7",
            "d925a1a2d2d5493a9468a7799c5e6b8e",
            "ba0ff05e76c5481581346f4cd3fb774a",
            "8d491e898ec44b5d9f941a662ab01c91",
            "bc0f0f1fb3d04c18945036ded388c8d2",
            "6922ab195e37431a91cc2712dc31a0e8",
            "0d42da98c4c844ea912712a7b562ac6b",
            "a08388773de34fa1b40504338262a661",
            "01545dc4eb1b4e0c94282bef9f5b3b92",
            "4522fb81c6cd4f5dadb90c4903decc35",
            "6969264b093c4c148f46a8082f8f82cf",
            "76f872ee420a41cf96c5af61a7dfc2bf",
            "14064bf84af04ee2b9a6c2b824e3c491",
            "0deffd6cc91540148f98aa2740da88b5",
            "5ba604ccd4634900ad60cf716104c19c",
            "008c706787c54bcb968a6c490c80f88a",
            "1d5da3b3c2fe415c8055ab250093441f",
            "b5b33671df374cb19675a2cbb694b6e4",
            "bf91dfdb170e4bcc98affd9e39bcae46",
            "6cc31714c48f4f44890f21a7e43efd3a",
            "0af390fa821a44b5973ac9d7b07264c5",
            "c36f80a0b149452dba416be270728514",
            "81434069f8604e038599bd4531037a5e",
            "d17c4355a0b141d2af3a61bacaad2d1e",
            "fa22b43e9ab643539adcf26ba7a62f8e",
            "b8ca33e7b7024eb88445a4389a4e6d3b",
            "9d07f36bb84b40b1a25826b2b5df1ae6",
            "aad8d35d89fa4a42aaed5d41a1ee8dcd",
            "506276856a2c49c6942ca8edab6fc89d",
            "d649d4ef29114a9ab2022b2b37547d8d",
            "4419519a029f48d7a93336bbc18375eb",
            "74329b06572f4e90b65fbf72d389a492",
            "f553ccb143444e2ebb2cbdab7d098e66",
            "a8410a4ddb274d3b8b1e632ad1f8a294",
            "3e4b6cfb21fc434d9db26c8250b3e0c1",
            "afe573d2e63a4ce296e835f7e25aecde",
            "094f783f34a14039852d15f65274e868",
            "6a215c1c7834493da38b92161eda92bf",
            "7b6f163b062b49ec85423e71621c1bba",
            "453012e2b58e43999abe77b8dffd6190",
            "a0efb70efbe0468a90f8ab691b4e95cd",
            "e5745ef5f1c14f3c9749f4a151f994cf",
            "9cde78bcc39142b8b9a8ea5a4fbdf799",
            "3885883f87074baf9a3b2c2537288d9b",
            "d32f6271f2644f84856b404f7ae0a04c",
            "b62c37306b5f4a00ac062cfd035bfcc6",
            "1e63b49bf45d49689fe697f6d6cfbd46",
            "f8ac917c6b3742c5a2f0a28488215d2c",
            "977db882498f401eb4aac041336691ab",
            "3d02d4c8c72d43da8f79a358316dc4a4",
            "256f20a4ce0b4cb7ba47cea8cb7b54dc",
            "757e8a5ddc134fd8b1a5eca2fad1e02e",
            "cf3dcbcfdde24bae83cb4175570b5b2d",
            "d9a440805908492eb6379968245b0843",
            "a70d0207575647d6b85898e08fcd1b63",
            "623ddc90a5ff4396895feebda25b6e0d",
            "07284d694be44c5d8810866be4b34ea1",
            "d4a0b20459cf49f0b4f0bd370e9be979",
            "2a9d949adea641189e363ca39ad16983",
            "c14852831a95440299755357f44cd139",
            "5735f15e46d4456b9683bd2127fcc11d",
            "ebf30b913400437987ddca354e0484bd",
            "b2e23ada5a2644baae6b76fb20a71293",
            "ffdeeae78d5b471f9cbe2c169809d5aa",
            "1216317eea0e41b4ac238c00c8b36d46",
            "4581c6dcb7e449fea939ce4fe44c9eac",
            "75576df775ea4394891a78a2f0ef61d1",
            "476ecbfa8ca1447fbff5d5793b45a3ea",
            "9d3edc43dc254641a68532abec257211",
            "78fba923fb124d9aa8035b7a715942ed",
            "3a4e230d5c474253b437e55ae6d6446a",
            "18a266b9b26d4d8aaf2261aa57f76175",
            "b54dc48c85e34a5fb8124a7fb4cf9ec3",
            "1a910930c7b34728b04420e18665e53b",
            "02251900670c46b6a273787a09ca976d",
            "de7c2caaa5114ef19a784b23bee16a6a",
            "2eb4f08aa1394aff91082fd3d7a0ae6a",
            "270038fdfce54129bcfbab84ff975198",
            "6d12c7d791b7421d98f72165d8dc05ef",
            "27787c4e55ce433185957e9e93ff0600",
            "be9bb27f49424a418291423692b83aba",
            "81d2710fccd94d04abb92e888baff7e0",
            "b4f299bbe1fe432ca4d6021791742ba6",
            "a43e4ba15523474d84d1b74a9bac5fab",
            "5a5770bdb5d4488bb93c16522b7b4c22",
            "b667f3edb55d4146b25e04feab05fa24",
            "3402ea75f9de4de997d31a355b6fc5bc",
            "1ea7b849f88f49ba84cd1834de33c8cb",
            "04b521f97b87416b86eac4b83c605a51",
            "9b64c6a633924858b296d6fdd7a0f10f",
            "7da8ad8a665c48ada328c3b5c4b75ae9",
            "2101cd9ff4414b1aa62392c27c615584",
            "a44fdfecbf8d4eac97495c2a7970a826",
            "7762859f4f8c494cb74fb396990d07b1",
            "9b198a8507a94be8ba92942612b2663b",
            "6fc52129df1c43d1975a17cf86c611a7",
            "350ba0343659400a8f9a36deef440d47",
            "519dbb2aa65b480fa7fef2075af60d38",
            "d9f49a0663eb4fc2bb628854f61ebe81",
            "d1af9ca49e23495dbf1a4d6de111983f",
            "aa97be034c304710924ded4ce726d81f",
            "1a5361048d9443dfb5a8b4ee198b2ca0",
            "074fcf67f0f14b879c4965efda2ad291",
            "6163a780b2714e57b68b3724f4dfaedf",
            "9325318f104d4c19a6a9c7ad6768da43",
            "184eb27fa8ff454e8a2176f7ceeeb259",
            "fd7a6462762a45c2af5934d78edaa605",
            "b648ad2480564896a482f9e45ce98307",
            "efb34746b98a45b09d453d294abb0ae5",
            "a7b02ec08e6543e78e3464414771c1a7",
            "e4e4ad38979c450a9c399ef7b11dd0e5",
            "6b88387eac2643fb8842479c33dc4f0e",
            "bb74564470e7487493c6b42a8c1e6c50",
            "44670c4a161c42c3889ebde3c2156bbf",
            "52e69ef30b5c4237b6f105631498991b",
            "3891cf2b960c4ab7aafd2ee46a3e6381",
            "489166f8b0b24ebc834366df7c5c267b",
            "697e35d7ae9e4aa9a34ca9d2e2b0b18f",
            "0578810e6f974947b3546112fe24a7a1",
            "8f29809a7a314bddae8b78998aed070e",
            "6deaee8894064d76af7b1b57eb07aaa2",
            "270edc178942410895158ee39f55687e",
            "6383760e0d5f4aeab02e83ea1b44290c",
            "8178a4c614ab449fab8e297b32649c78",
            "bf8588ba8fc440019bf2e2961009b45a",
            "699320aee4344099acac49561ec708ba",
            "2ca253d225d8451393ab959f8fa741ef",
            "d5a3fe6200514685a62aedf50db6e219",
            "094e2d59d10a40fe949c5403a20fa4f1",
            "5d68f0a6a7cb4f9688c46ee7aa1bf702",
            "5d7e83fe45d44e58a21ddaded8076af7",
            "20e07c1412d84c2191fcc4a665f3d07a",
            "1b9b435e66b646c9b941af6f70c95eab",
            "115f7634deee46e7ab29eb3286451f92",
            "a4b754de2d25494a9be1953e181fd2be",
            "1094be752d784f66a1a781272a2da672",
            "77235a2a91154f9a926afe16944fc2dd",
            "bf2b01f995294c0c9e2cb26e853d92c5",
            "2e896b94a1bd47fb9eff86bd13fd9a80",
            "e5f5d6b2ed484e00a9642ec426b867fe",
            "fa770bcf00e74d30ac389f6aea61e53b"
          ]
        },
        "id": "pRJZE5tVlIg8",
        "outputId": "9ab482b0-42a9-4a07-a061-c54fcdddfed1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b75c263d4bf24f65904f2ab140191308",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20f4a91db2734ed08bba141babb99687",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "524d701b8d944900aed31a2c0ff47682",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3beff2f7da5049e8a201588875fc403a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bc9b8b3fea84bc9b2a5e185bc9a59b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/632 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b00ddfb86f6c46d4bdc8a605a7d05408",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4522fb81c6cd4f5dadb90c4903decc35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0af390fa821a44b5973ac9d7b07264c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74329b06572f4e90b65fbf72d389a492",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cde78bcc39142b8b9a8ea5a4fbdf799",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/28.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9a440805908492eb6379968245b0843",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1216317eea0e41b4ac238c00c8b36d46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/154 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de7c2caaa5114ef19a784b23bee16a6a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/6.72k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3402ea75f9de4de997d31a355b6fc5bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/299M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "519dbb2aa65b480fa7fef2075af60d38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/23.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efb34746b98a45b09d453d294abb0ae5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/650000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f29809a7a314bddae8b78998aed070e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d7e83fe45d44e58a21ddaded8076af7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='812' max='812' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [812/812 15:31, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.651000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.455500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.438100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.462100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.437200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.439000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>2.495100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.427700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>2.409000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.397100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>2.428700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>2.428800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>2.431900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>2.385300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.415900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>2.469400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>2.477000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>2.418500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>2.446900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.401700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>2.397800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>2.310000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>2.378100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>2.325100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>2.376300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>2.480900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>2.392800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>2.319400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>2.340300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.319900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>2.297700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>2.381900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>2.410200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>2.411600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>2.418900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>2.383200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>2.334000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>2.351200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>2.355700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.444600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>2.317100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>2.373800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>2.369500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>2.330400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>2.366400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>2.376600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>2.339400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>2.311000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>2.393800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.380500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>2.360500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>2.361400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>2.324900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>2.317100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>2.392600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>2.375500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>2.404700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>2.363900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>2.397200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>2.354800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>2.337000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>2.287300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>2.356100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>2.380800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>2.431500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>2.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>2.290400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>2.332500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>2.363200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>2.363000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>2.392900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>2.304400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>2.344700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>2.383700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>2.315000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>2.337000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>2.327500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>2.370100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>2.421900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>2.388400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>2.354000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=812, training_loss=2.3820426258547553, metrics={'train_runtime': 934.0883, 'train_samples_per_second': 6.959, 'train_steps_per_second': 0.869, 'total_flos': 3.306328265903309e+16, 'train_loss': 2.3820426258547553, 'epoch': 0.9993846153846154})"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling, BitsAndBytesConfig\n",
        "from datasets import load_dataset\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from huggingface_hub import login\n",
        "\n",
        "# デバイス確認（T4 GPU が見えるか）\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Running on {device}\")\n",
        "\n",
        "# 1. モデルとトークナイザの準備\n",
        "# model_name = \"rinna/japanese-gpt2-small\"\n",
        "model_name = \"elyza/ELYZA-japanese-Llama-2-7b\"\n",
        "\n",
        "# 8bit量子化の設定\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    llm_int8_threshold=6.0,\n",
        "    llm_int8_has_fp16_weight=True\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16  # T4 GPU に最適\n",
        ")\n",
        "\n",
        "# # Instead, move the model to the device explicitly after loading.\n",
        "# model.to(device)\n",
        "\n",
        "# # 2. LoRAの設定 GPT2系のrinna/japanese-gpt2-smallの場合（PEFT）\n",
        "# lora_config = LoraConfig(\n",
        "#     r=8,\n",
        "#     lora_alpha=32,\n",
        "#     target_modules=[\"c_proj\", \"c_attn\"],  # Changed target modules to match GPT2 architecture\n",
        "#     lora_dropout=0.05,\n",
        "#     bias=\"none\",\n",
        "#     task_type=TaskType.CAUSAL_LM\n",
        "# )\n",
        "\n",
        "# 2. LoRAの設定 Llama2系 ELYZAの場合\n",
        "  # モジュール名\t用途・場所\n",
        "  # q_proj\tAttentionのQuery部分\n",
        "  # k_proj\tAttentionのKey部分\n",
        "  # v_proj\tAttentionのValue部分\n",
        "  # o_proj\tAttentionの出力変換部分\n",
        "  # gate_proj\tMLP(FFN)部のGating層\n",
        "  # up_proj\tMLP(FFN)部の中間変換層\n",
        "  # down_proj\tMLP(FFN)部の出力層\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    target_modules=[\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",  # Attention\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\"      # MLP\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# 3. データセット読み込みと前処理（FineTuningデータの例: yelpレビュー → 日本語のテキストに置き換えるべき）\n",
        "dataset = load_dataset(\"yelp_review_full\", split=\"train[:1%]\")  # 小さめで検証\n",
        "\n",
        "# テキストをトークン化（単純化）\n",
        "def tokenize_fn(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_fn, batched=True)\n",
        "\n",
        "# 4. トレーニング引数の設定\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    num_train_epochs=1, #本当は3回ぐらい回したい\n",
        "    fp16=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# 5. トレーナー定義と学習開始\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCcvffwb03A4"
      },
      "source": [
        "# Fine-Tuning後のモデルを利用して推論(Chat)を実行\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgkO4WOVlnAO",
        "outputId": "3532c146-ba21-4dfb-ea12-5a7da0fd11fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧠 回答: 富士山。\\n\\n僕は昨年まで、40-60日/年に何度も来ていただけに、この評価は結構難しくなりました。\\n\\nある人が言ったように、「The best way to learn a city is to live in it for one year, but the second best way is to visit it once.\\\" I'm not sure that the second best way will even do this restaurant justice.\\n\\nA\n"
          ]
        }
      ],
      "source": [
        "from transformers import GenerationConfig\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# より構造化されたプロンプト（LoRAで学習している形式に合わせること）\n",
        "prompt = \"質問：日本で一番高い山は何ですか？\\n回答：\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# 推論設定\n",
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=128,\n",
        "    do_sample=True,\n",
        "    top_p=0.95,\n",
        "    temperature=0.7,\n",
        "    repetition_penalty=1.1,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    bos_token_id=tokenizer.bos_token_id\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        **inputs,\n",
        "        generation_config=generation_config\n",
        "    )\n",
        "\n",
        "# 出力をプロンプトと分離して表示\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(\"🧠 回答:\", generated_text.replace(prompt, \"\").strip())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "authorship_tag": "ABX9TyOXZLEBy07KnyWQDO2oqp5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}