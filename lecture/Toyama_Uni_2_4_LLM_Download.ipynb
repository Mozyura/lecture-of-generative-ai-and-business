{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takedatmh/toyama/blob/main/Toyama_Uni_2_4_LLM_Download.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk5_bZaHk4YA"
      },
      "source": [
        "#1.必要なライブラリのインストール\n",
        "\n",
        "まず、Hugging FaceのTransformersライブラリをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_e68zp7kMXR",
        "outputId": "5073f810-4c10-4152-8ae1-67d864d6ea26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZuKLrLElEZK"
      },
      "source": [
        "#2.モデルとトークナイザーのロード\n",
        "\n",
        "次に、rinna/japanese-gpt2-smallモデルと対応するトークナイザーをロードします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319,
          "referenced_widgets": [
            "0bd6142961cb4298bf280328b4f9438c",
            "a48c211b49854411a72f143d31d21edc",
            "3aef63025b5c430083cb130095e94b12",
            "f357d20e9a23419d802ec9a3ffe433e2",
            "bc710b7ea1364ccf857f066371353ac9",
            "833eedccfbb34cba8b07df0ebde9356e",
            "31eda9fcffbb4d88aa8ffed118ed185b",
            "b50099b50f43428ba87c38ee39eddcb6",
            "204cd5daf5904e819e49a889bcf83b91",
            "e05f3f1b63bc4c5a9f94e684203b7e4f",
            "855b65bed44445709997b06766ebd6bc",
            "2b31f95605764100ae971ab6e957ee87",
            "b4e74aeec0ad4a9c879276c83aafe056",
            "6160b98aeff947a998599ce8431e04ee",
            "921a5f8fc18742fbb5026af4c550b59b",
            "8d5694e3ce8d4186b5f1c26b1a65b63d",
            "a9cc26541cb64a669329ff4831726608",
            "38cf46d841a24a0a861c9176c1c833dd",
            "2eecdfc3e8394759905d6d9d8e4c41c8",
            "6bf5598b5cb449b4885aceebac7f78bc",
            "478068b19c024e2299808418d430053c",
            "bdfcf362e61e4d198edb68b8a8de65d1",
            "122f3e56e50c455f8fd032c34be4d3ec",
            "2f236c5001af4b2f92b08a105ed1347d",
            "9042a79f008e40fc992fb77652e978b7",
            "af838e4a4dcd4af092a0ed01a06fcf15",
            "40132c7ff0d844ec8e8c8041b32d1b9e",
            "76f794716e834945831b13a92e93ccc5",
            "c7f142af3b204676b71b95be4103f1de",
            "3c42aea6cc1a4fbc94942f435cdbfeac",
            "1d41e059a83d4150ae35e9ab0f4c19e0",
            "794888fc843047698a5a3f2db3a3abed",
            "132065ce55fd4224b38b308355b5ded8",
            "0c0f2f5438394d758c835ddb84a40827",
            "bc9db09d56f64cb1b6a2b8d44e3db6c0",
            "9fa9dbf963544330aed3294f65766441",
            "2a04427b6a4145318d6e13a9de90e033",
            "70eba064e3c045b0b5a93b0026d5cca7",
            "a54c982a89864bac848af3c40c4dc411",
            "d13edbea90a14a4cbe4c44ed370b698f",
            "edc41c25771c40e89f7276846c7be13a",
            "089f53b7da8047808159bebb93cebca1",
            "a3592f3065d84f87a6edd791774d1f46",
            "8cc95a037112440b888f343a14c5bd80",
            "59d1f7591e7c4dedb7259cd61813333e",
            "16b8a4ceb36d48a883f87fa917522464",
            "adce96ebef5c49ab9014c291cac74f6c",
            "1351b21f0b41440f8c2a585c2cb89e0c",
            "b813e6008224496e9412519edbda7494",
            "7a6c9b10efd24e01b6500f10820dd973",
            "d76ad048cdd04d1f9cd6b11adf226029",
            "604f4809ad924708a5d5552b4c6ced4e",
            "b766d77b09b846f286295be72216f14c",
            "6aa680210ec14217930186141f8b0769",
            "22e25094dc5c41148b93232b63c3ed95"
          ]
        },
        "id": "G2bD-lY8keMA",
        "outputId": "67b69f57-e2b9-41dd-f6da-6a36951a3953"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bd6142961cb4298bf280328b4f9438c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/282 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b31f95605764100ae971ab6e957ee87",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/806k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "122f3e56e50c455f8fd032c34be4d3ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/153 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c0f2f5438394d758c835ddb84a40827",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59d1f7591e7c4dedb7259cd61813333e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/454M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# トークナイザーのロード\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"rinna/japanese-gpt2-small\", use_fast=False)\n",
        "tokenizer.do_lower_case = True  # 一部のバグ回避のための設定\n",
        "\n",
        "# モデルのロード\n",
        "model = AutoModelForCausalLM.from_pretrained(\"rinna/japanese-gpt2-small\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDJFCSxGlIhO"
      },
      "source": [
        "#3.モデルのデバイスへの配置\n",
        "\n",
        "Google ColabでGPUを使用する場合、モデルをGPUに配置します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VziBmQd7koTn",
        "outputId": "0ba2f6b5-c023-4174-f584-74ab621b244b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(32000, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHTVcG3MlhM6"
      },
      "source": [
        "#4.テキスト生成の実行\n",
        "\n",
        "以下のコードで、モデルを使用して日本語のテキスト生成を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjV2oxX5lkYg",
        "outputId": "67d11dbb-cbda-4544-df33-90a1f1415a73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "良い天気ですね昨日は、いつもの通り、午後から、実家に、今年も、お世話になっている、 で、昨日から、京都と青森へ、友達とのお茶会をしたり、晩酌を頂きました 昨日の、会社の先輩の、私の友人のおかげで、とても、良い買い物ができました まず、皆が、飲み会で行きたくて行った、私の母校、立命館大学に 学生生活では、色んなイベントがあります\n"
          ]
        }
      ],
      "source": [
        "# 入力テキストの設定\n",
        "input_text = \"良い天気ですね\"\n",
        "\n",
        "# トークナイズとテンソル変換\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# テキスト生成\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=100,\n",
        "    num_return_sequences=1,\n",
        "    no_repeat_ngram_size=2,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    temperature=1.0,\n",
        "    do_sample=True,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "# 生成されたテキストのデコード\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w4P49ZSmgIa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1nibXuJQc7dQJ0iO0qyJ_4ayVnVMJRYsH",
      "authorship_tag": "ABX9TyNiseY1/jRrGI1DkmAdr7xW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}