{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takedatmh/toyama/blob/main/Toyama_Uni_2_4_MLL_Load.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwyuOKrepvLu"
      },
      "source": [
        "# 1. 必要なライブラリをインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scudf2K8nSB3",
        "outputId": "dc76ca2a-7b7c-4de5-dd05-6af7c2c78840"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaMY7dCxqLh_"
      },
      "source": [
        "# 2. 必要なモジュールをインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brT7ndr5pt-U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cw39BXLqPjt"
      },
      "source": [
        "# 3. デバイスの確認（GPUを使用する）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKSBT_WKqRQw"
      },
      "outputs": [],
      "source": [
        "device = 0 if torch.cuda.is_available() else -1  # T4 GPU がある場合は 0、なければ CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyrNdcPQqTmy"
      },
      "source": [
        "# 4. pipeline を使用してテキスト生成用パイプラインを構築"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "d542c331782949888742254cfbc41e13",
            "253595de8c94426fb85c534536aad299",
            "fa27dc17716041f288968c694d3aa055",
            "785888c5c8424da0bab1d3f32d1a472f",
            "8f5c2f6effa243c883709a5e056e2af6",
            "7f670d84ad22436eb572d82717212100",
            "c1b44b48de844a1e9f4f87944f4435b3",
            "324444e824b64e5c9bbc9f1508a9b0a1",
            "6a8f4684eb7b40c0b2c867d942d939d2",
            "72e82cdf59054b30b4e60cb76a56f75b",
            "db5042175a834c718fa56d04c0677658",
            "2fb4014779ee49a19a374d5ef372158c",
            "a49951f5eb2c47208e5b0a952d863057",
            "40fc4cc62c6f4334a8d559070d1c43c7",
            "c8c382bd53fa44029ee77abe095a5af7",
            "43335c6f6ebd43faad4a3415dd9a7618",
            "b4ac00799327422f9c2bcefc1364d44e",
            "c3f0b17346554fe49f01aa8245ba7ac7",
            "3b6ca50a773843fe9cfab22edb701540",
            "9e87070af7af4a5cbd111c564b357f66",
            "425baca035a74be9a4f1327e5b861118",
            "efd30dc340de48c79b5faf60993ffa43",
            "f0637130f505422b96b45a99e020fabe",
            "2edf728d1fee4ce4b694688966e890f8",
            "3e6819a807824e51b80a45c09cfa11cd",
            "51529632446746bc93873bc0704d5464",
            "19c43136541741f188d8f382654b9b60",
            "5fd36f3ddebe427fae294adba64d741b",
            "ac85aa34bb7b47528afd9aecc6e32a16",
            "020cf72d9b764ee484f7845f2111c2e2",
            "ac7ec2a4a22a4ceb8f9fdb5b6e7928ae",
            "6ac39f02407f463f9fb1e246ae7e2421",
            "08973ec4874944c0b719afa9cfc49423",
            "ba05764d84d74a8ba417fcab118acaa3",
            "89572e68c061455790deee2ba80517ed",
            "2087061c0b1c4778aae63ce7d29e0818",
            "9baf9caa497340a5a41457efb2971581",
            "b72642be8a85466f93293d801090ae1a",
            "dd89b1c6a9d040cbadcd88717fa284ab",
            "2994b132ea1b4242a23cdce1c39d4c56",
            "08f9ed7e18e046a6abbb3d7aa875dc95",
            "62270257a07046b9b37beb4e0a84209f",
            "270e5ded31534a59bbb5d7ccf7d94ab0",
            "33d7429de4c4467fa2ce1c88abc3d45e",
            "42ba03544b49480d81f02ccfb1810e8c",
            "bb80ab808d9a4822816b16094900dbd3",
            "5c474c9038364e0fa10b33a484d05c29",
            "3e71967f3fc94977b142fc00060df694",
            "4b3fa2b5677940258df161372f0e5250",
            "0a139c2f1f264964a25ec3bb3344c687",
            "99caa3f656b84b039a9b044a8907a2af",
            "44ef9f694359419f84b78418a12fd62e",
            "6858393cb2ae47aaa1d7601a14ed5461",
            "c3dad8c4c8c74f0bb83b8e30c23fbf6e",
            "531390890792421ab6916852e410cb4e"
          ]
        },
        "id": "w_vggeLfqWW4",
        "outputId": "4efad3ef-b418-4f39-eab2-81927d3fa695"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d542c331782949888742254cfbc41e13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fb4014779ee49a19a374d5ef372158c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/454M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0637130f505422b96b45a99e020fabe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/282 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba05764d84d74a8ba417fcab118acaa3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/806k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42ba03544b49480d81f02ccfb1810e8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/153 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "text_generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"rinna/japanese-gpt2-small\",\n",
        "    tokenizer=\"rinna/japanese-gpt2-small\",\n",
        "    device=device  # GPU（0）か CPU（-1）\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxytrK3yqYqB"
      },
      "source": [
        "# 5. 入力テキストを指定して生成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-pO4adxqalC",
        "outputId": "d08fa901-34ce-4756-bbed-19cc56a3b650"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ],
      "source": [
        "input_text = \"今日はとても良い天気ですね。\"\n",
        "\n",
        "result = text_generator(\n",
        "    input_text,\n",
        "    max_length=50,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    temperature=1.0,\n",
        "    num_return_sequences=1,\n",
        "    pad_token_id=text_generator.tokenizer.eos_token_id  # GPT2系はEOSトークンでパディング\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQgxbL6Fqc_0"
      },
      "source": [
        "# 6. 結果の出力"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hiZW2X4qebT",
        "outputId": "34386381-a0d2-419b-c019-d03b3be55e50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "今日はとても良い天気ですね。私の地元では朝から朝食を頂くのですが、昨日は夜に冷えるということで、少しだけ食べ過ぎてしまいました。 今日も朝から気温が下がっており\n"
          ]
        }
      ],
      "source": [
        "print(result[0][\"generated_text\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOY1VcAbOcGEfMjoJUQaYny",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}